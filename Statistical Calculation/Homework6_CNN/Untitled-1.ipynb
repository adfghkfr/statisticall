{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis \\\n",
    "import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis \\\n",
    "import QuadraticDiscriminantAnalysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as LA\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.neighbors as neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets, neighbors\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 生成兩群組模擬資料\n",
    "def param(n1, n2, mean1, mean2, mean3, mean4, val1, val2):\n",
    "    m1, m2 = np.array([mean1, mean2]), np.array([mean3, mean4])\n",
    "    Cov1 = np.array([[1, val1], [val1, 1]])\n",
    "    Cov2 = np.array([[1, val2], [val2, 1]])\n",
    "    mvn1 = multivariate_normal(mean = m1, cov = Cov1)\n",
    "    mvn2 = multivariate_normal(mean = m2, cov = Cov2)\n",
    "    A = mvn1.rvs(n1)\n",
    "    B = mvn2.rvs(n2)\n",
    "    Xvar = np.vstack((A, B))#2000*1矩陣\\\n",
    "    y = np.hstack((np.zeros(n1), np.ones(n2)))#2000\n",
    "    param = np.c_[Xvar, y]\n",
    "    return param\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 生成三群組模擬資料\n",
    "def param3(n1, n2, n3, mean1, mean2, mean3, mean4, mean5, mean6, val1, val2, val3):\n",
    "    m1, m2, m3 = np.array([mean1, mean2]), np.array([mean3, mean4]), np.array([mean5, mean6])\n",
    "    Cov1 = np.array([[1, val1], [val1, 1]])\n",
    "    Cov2 = np.array([[1, val2], [val2, 1]])\n",
    "    Cov3 = np.array([[1, val3], [val3, 1]])\n",
    "    mvn1 = multivariate_normal(mean = m1, cov = Cov1)\n",
    "    mvn2 = multivariate_normal(mean = m2, cov = Cov2)\n",
    "    mvn3 = multivariate_normal(mean = m3, cov = Cov3)\n",
    "    A = mvn1.rvs(n1)\n",
    "    B = mvn2.rvs(n2)\n",
    "    C = mvn2.rvs(n3)\n",
    "    Xvar = np.vstack((A, B, C))#2000*1矩陣\\\n",
    "    y = np.hstack((np.zeros(n1), np.ones(n2), np.ones(n3)+1))#2000\n",
    "    param3 = np.c_[Xvar, y]\n",
    "    return param3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear training Error:0.0541\n",
      "Linear testing Error:0.0552\n",
      "Aug training Error:0.0309\n",
      "Aug testing Error:0.0297\n",
      "LDA training Error:0.0541\n",
      "LDA testing Error:0.0552\n",
      "QDA training Error:0.0300\n",
      "QDA testing Error:0.0350\n",
      "KNN training Error1:0.0312\n",
      "KNN testing Error1:0.0350\n",
      "ANN training Error1:0.0000\n",
      "ANN testing Error1:0.0000\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 兩群組資料生成\n",
    "# ------------------------------------------------\n",
    "D = param(500, 500, 2, 2, 4, 1, 0.9, 0.3)\n",
    "data = X = D[:, 0:2]\n",
    "label = y = D[:, 2]\n",
    "# --------------------------------------------------------------\n",
    "# 加廣線性迴歸與簡單線性迴歸\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# -----------------------------------------------\n",
    "n =100 #模擬次數\n",
    "Lineartrainerror = np.zeros(n)\n",
    "Lineartesterror = np.zeros(n)\n",
    "Augmentedtrainerror = np.zeros(n)\n",
    "Augmentedtesterror = np.zeros(n)\n",
    "Logistictrainerror = np.zeros(n)\n",
    "Logistictesterror = np.zeros(n)\n",
    "\n",
    "LDAtrainingError = np.zeros(n) #用來存取訓練誤差\n",
    "LDAtestingError = np.zeros(n) #存取測試誤差\n",
    "QDAtrainingError = np.zeros(n)\n",
    "QDAtestingError = np.zeros(n)\n",
    "KNNtrainingError = np.zeros(n)\n",
    "KNNtraingError = np.zeros(n)\n",
    "\n",
    "ANNtrainerror = np.zeros(n)\n",
    "ANNtesterror = np.zeros(n)\n",
    "\n",
    "# ------------------------------------------------\n",
    "#載入套件\n",
    "Lda = LinearDiscriminantAnalysis(tol = 1e-6)\n",
    "Qda = QuadraticDiscriminantAnalysis(tol = 1e-6, store_covariance = True)\n",
    "Mdl = LinearRegression()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(multi_class='multinomial',solver='lbfgs',class_weight='balanced',max_iter=1000)\n",
    "\n",
    "K1 = 5\n",
    "weights = \"uniform\"\n",
    "Knn = neighbors.KNeighborsClassifier(K1, weights = weights)\n",
    "\n",
    "hidden_layers = (30, )\n",
    "solver = \"adam\"\n",
    "clf = MLPClassifier(max_iter = 10000, solver = solver,\n",
    "hidden_layer_sizes = hidden_layers, verbose = True,\n",
    "activation = \"logistic\", tol = 1e-6, random_state = 0)\n",
    "\n",
    "# ------------------------------------------------\n",
    "for i in range(n) :\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    # --------------------------------------------------\n",
    "    Mdl.fit(X_train, y_train) \n",
    "    y_hat = Mdl.predict(X_train) \n",
    "    y_pretrain = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "    Lineartrainerror[i] = 1- np.mean(y_pretrain == y_train)\n",
    "\n",
    "    y_hat = Mdl.predict(X_test) \n",
    "    y_pretest = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "    Lineartesterror[i] = 1 - np.mean(y_pretest == y_test)\n",
    "    # ---------------------------------------------------\n",
    "    x1 = X_train[:,0:1] \n",
    "    x2 = X_train[:,1:2]\n",
    "    XX = np.hstack((x1, x2, x1 * x2, x1 ** 2, x2 ** 2))\n",
    "    Mdl.fit(XX, y_train) \n",
    "    y_hat = Mdl.predict(XX) \n",
    "    y_pretrain = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "    Augmentedtrainerror[i] = 1 - np.mean(y_pretrain == y_train)\n",
    "\n",
    "    x1 = X_test[:,0:1]\n",
    "    x2 = X_test[:,1:2]\n",
    "    XX = np.hstack((x1, x2, x1 * x2, x1 ** 2, x2 ** 2))\n",
    "    y_hat = Mdl.predict(XX) \n",
    "    y_pretest = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "    Augmentedtesterror[i] = 1 - np.mean(y_pretest == y_test)\n",
    "    # ---------------------------------------------------\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_predict = logreg.predict(X_test)\n",
    "    Logistictrainerror[i] = 1 - logreg.score(X_train, y_train)\n",
    "    Logistictesterror[i] = 1 - logreg.score(X_test, y_test)\n",
    "    # ---------------------------------------------------\n",
    "    Lda.fit(X_train, y_train)\n",
    "    Lda.predict(X_test)\n",
    "    LDAtrainingError[i] = 1 - Lda.score(X_train, y_train)\n",
    "    LDAtestingError[i] = 1 - Lda.score(X_test, y_test)\n",
    "    # ---------------------------------------------------\n",
    "    Qda.fit(X_train, y_train)\n",
    "    Qda.predict(X_test)\n",
    "    QDAtrainingError = 1 - Qda.score(X_train, y_train)\n",
    "    QDAtestingError = 1 - Qda.score(X_test, y_test)\n",
    "    # ---------------------------------------------------\n",
    "    Knn.fit(X_train, y_train)\n",
    "    Knn.predict(X_test)\n",
    "    KNNtrainingError1 = 1 - Knn.score(X_train, y_train)\n",
    "    KNNtestingError1 = 1 - Knn.score(X_test, y_test)\n",
    "    # ---------------------------------------------------\n",
    "    #clf.fit(X_train, y_train)\n",
    "    #y_test_hat = clf.predict(X_test)\n",
    "    #ANNtrainerror[i] = 1 - clf.score(X_train, y_train)\n",
    "    #ANNtesterror[i] = 1 - clf.score(X_test, y_test)\n",
    "\n",
    "#print出bootstrapping抽取K次的訓練誤差平均值\n",
    "print(\"Linear training Error:{:.4f}\".format(Lineartrainerror.mean()))\n",
    "print(\"Linear testing Error:{:.4f}\".format(Lineartesterror.mean()))\n",
    "print(\"Aug training Error:{:.4f}\".format(Augmentedtrainerror.mean()))\n",
    "print(\"Aug testing Error:{:.4f}\".format(Augmentedtesterror.mean()))\n",
    "\n",
    "print(\"LDA training Error:{:.4f}\".format(LDAtrainingError.mean()))#除了平均數也可以看看變異數\n",
    "print(\"LDA testing Error:{:.4f}\".format(LDAtestingError.mean()))\n",
    "print(\"QDA training Error:{:.4f}\".format(QDAtrainingError.mean()))#除了平均數也可以看看變異數\n",
    "print(\"QDA testing Error:{:.4f}\".format(QDAtestingError.mean()))\n",
    "print(\"KNN training Error1:{:.4f}\".format(KNNtrainingError1.mean()))#除了平均數也可以看看變異數\n",
    "print(\"KNN testing Error1:{:.4f}\".format(KNNtestingError1.mean()))\n",
    "\n",
    "print(\"ANN training Error1:{:.4f}\".format(ANNtrainerror.mean()))#除了平均數也可以看看變異數\n",
    "print(\"ANN testing Error1:{:.4f}\".format(ANNtesterror.mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054075000000000005\n",
      "0.05520000000000001\n",
      "0.03088749999999999\n",
      "0.02970000000000003\n",
      "0.031187499999999993\n",
      "0.02925000000000003\n",
      "0.054075000000000005\n",
      "0.05520000000000001\n",
      "0.030000000000000027\n",
      "0.03500000000000003\n",
      "0.03125\n",
      "0.03500000000000003\n"
     ]
    }
   ],
   "source": [
    "print(Lineartrainerror.mean())\n",
    "print(Lineartesterror.mean())\n",
    "print(Augmentedtrainerror.mean())\n",
    "print(Augmentedtesterror.mean())\n",
    "print(Logistictrainerror.mean())\n",
    "print(Logistictesterror.mean())\n",
    "\n",
    "print(LDAtrainingError.mean())\n",
    "print(LDAtestingError.mean())\n",
    "print(QDAtrainingError.mean())\n",
    "print(QDAtestingError.mean())\n",
    "print(KNNtrainingError1.mean())\n",
    "print(KNNtestingError1.mean())\n",
    "#print(ANNtrainerror.mean())\n",
    "#print(ANNtesterror.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in training for augmented regression: 0.0563\n",
      "Accuracy in training for augmented regression: 0.0400\n"
     ]
    }
   ],
   "source": [
    "D = param(500, 500, 2, 2, 4, 1, 0.9, 0.3)\n",
    "data = X = D[:, 0:2]\n",
    "label = y = D[:, 2]\n",
    "# --------------------------------------------------------------\n",
    "# 加廣線性迴歸與簡單線性迴歸\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# -----------------------------------------------\n",
    "n =100 #模擬次數\n",
    "Lineartrainerror = np.zeros(n)\n",
    "Lineartesterror = np.zeros(n)\n",
    "Augmentedtrainerror = np.zeros(n)\n",
    "Augmentedtesterror = np.zeros(n)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    # --------------------------------------------------\n",
    "Mdl.fit(X_train, y_train) \n",
    "y_hat = Mdl.predict(X_train) \n",
    "y_pretrain = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "print(\"Accuracy in training for augmented regression: {:.4f}\".format(1 - np.mean(y_pretrain == y_train)))\n",
    "Lineartrainerror = 1 - np.mean(y_pretrain == y_train)\n",
    "\n",
    "y_hat = Mdl.predict(X_test) \n",
    "y_pretest = [1 if i > 0.5 else 0 for i in y_hat]\n",
    "print(\"Accuracy in training for augmented regression: {:.4f}\".format(1 - np.mean(y_pretest == y_test)))\n",
    "#Lineartesterror[i] = np.mean(y_pretest == y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5263c48ddfa36758767175d305ff19ced56d7c7302d90e4a7dee52d9491ebdf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
